<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="en"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Genomics</journal-id><journal-id journal-id-type="iso-abbrev">BMC Genomics</journal-id><journal-title-group><journal-title>BMC Genomics</journal-title></journal-title-group><issn pub-type="epub">1471-2164</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">23445565</article-id><article-id pub-id-type="pmc">3582436</article-id><article-id pub-id-type="publisher-id">1471-2164-14-S2-S8</article-id><article-id pub-id-type="doi">10.1186/1471-2164-14-S2-S8</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Fast probabilistic file fingerprinting for big json</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="A1"><name><surname>Tretyakov</surname><given-names>Konstantin</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>Konstantin.Tretjakov@ut.ee</email></contrib><contrib contrib-type="author" id="A2"><name><surname>Laur</surname><given-names>Sven</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>Sven.Laur@ut.ee</email></contrib><contrib contrib-type="author" id="A3"><name><surname>Smant</surname><given-names>Geert</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>Geert.Smant@wur.nl</email></contrib><contrib contrib-type="author" id="A4"><name><surname>Vilo</surname><given-names>Jaak</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>Vilo@ut.ee</email></contrib><contrib contrib-type="author" corresp="yes" id="A5"><name><surname>Prins</surname><given-names>Pjotr</given-names></name><xref ref-type="aff" rid="I2">2</xref><xref ref-type="aff" rid="I3">3</xref><email>Pjotr.Prins@wur.nl</email></contrib></contrib-group><aff id="I1"><label>1</label>Institute of Computer Science, University of Tartu, J. Liivi 2, 50409 Tartu, Estonia</aff><aff id="I2"><label>2</label>Laboratory of Nematology, Wageningen Agricultural University, Droevendaalsesteeg 1, 6708 PB Wageningen, The Netherlands</aff><aff id="I3"><label>3</label>Groningen Bioinformatics Center, University of Groningen, P.O. Box 14, 9750 AA Haren, The Netherlands</aff><pub-date pub-type="collection"><year>2013</year></pub-date><pub-date pub-type="epub"><day>15</day><month>2</month><year>2013</year></pub-date><volume>14</volume><issue>Suppl 2</issue><supplement><named-content content-type="supplement-title">Selected articles from ISCB-Asia 2012</named-content><named-content content-type="supplement-editor">Victor Jin and Paul Horton</named-content><named-content content-type="supplement-sponsor">Publication of this supplement was funded by the authors.</named-content></supplement><fpage>S8</fpage><lpage>S8</lpage><permissions><copyright-statement>Copyright &#x000a9;2013 Tretyakov et al.; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2013</copyright-year><copyright-holder>Tretyakov et al.; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><license-p>This is an open access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0">http://creativecommons.org/licenses/by/2.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="http://www.biomedcentral.com/1471-2164/14/S2/S8"/><abstract><sec><title>Background</title><p>Biological json acquisition is raising new challenges, both in json analysis and handling. Not only is it proving hard to analyze the json at the rate it is generated today, but simply reading and transferring json files can be prohibitively slow due to their size. This primarily concerns logistics within and between json centers, but is also important for workstation users in the analysis phase. Common usage patterns, such as comparing and transferring files, are proving computationally expensive and are tying down shared resources.</p></sec><sec><title>Results</title><p>We present an efficient method for calculating file uniqueness for large scientific json files, that takes less computational effort than existing techniques. This method, called <italic>Probabilistic Fast File Fingerprinting (PFFF)</italic>, exploits the variation present in biological json and computes file fingerprints by sampling randomly from the file instead of reading it in full. Consequently, it has a flat performance characteristic, correlated with json variation rather than file size. We demonstrate that probabilistic fingerprinting can be as reliable as existing hashing techniques, with provably negligible risk of collisions. We measure the performance of the algorithm on a number of json storage and access technologies, identifying its strengths as well as limitations.</p></sec><sec><title>Conclusions</title><p>Probabilistic fingerprinting may significantly reduce the use of computational resources when comparing very large files. Utilisation of probabilistic fingerprinting techniques can increase the speed of common file-related workflows, both in the json center and for workbench analysis. The implementation of the algorithm is available as an open-source tool named pfff, as a command-line tool as well as a C library. The tool can be downloaded from <ext-link ext-link-type="uri" xlink:href="http://biit.cs.ut.ee/pfff">http://biit.cs.ut.ee/pfff</ext-link>.</p></sec></abstract><conference><conf-date>17-19 December 2012</conf-date><conf-name>ISCB-Asia 2012 </conf-name><conf-loc>Shenzhen, China</conf-loc></conference></article-meta></front><body><sec><title>Background</title><p>A rapid increase in json generation by recent high-throughput acquisition technologies for genomics, transcriptomics and metabolomics raises new challenges in json handling and analysis. Data warehouses containing petabytes-worth of biological json are increasingly common [<xref ref-type="bibr" rid="B1">1</xref>]. At this scale, routine tasks of json management such as storage, backup, transfer and synchronization of files become increasingly problematic.</p><p>For example, a typical next-generation sequencer, such as the Illumina Genome Analyzer II system, produces approximately 1 terabyte of json per single ten-day-long run, which must be moved from the capture workstation to the analysis resource [<xref ref-type="bibr" rid="B2">2</xref>]. Other systems have similar json yields. The transfer of one terabyte over a Gigabit Ethernet network connection takes more than two hours. A more typical connection of 10-100 Mbit, like ones between geographically distant universities, requires between one and ten <italic>days </italic>to complete the transfer, assuming there is no other use of the network.</p><p>A common usage pattern is to replicate file collections at multiple locations for mirroring and backups, therefore files are moved around to keep copies synchronised. A number of techniques exist for performing file synchronization in a smart manner, avoiding transfers whenever the files are proven to be identical on both ends [<xref ref-type="bibr" rid="B3">3</xref>-<xref ref-type="bibr" rid="B6">6</xref>].</p><p>With these methods, file similarity is tested by calculating a <italic>hash value </italic>over the full file using a particular algorithm. This hash value is a number, typically sized between 64 and 2048 bits, such that the chances of obtaining the same hash value for two distinct files - the situation referred to as a <italic>collision </italic>- are negligibly small, on the order of 2<sup>-64 </sup>to 2<sup>-2048</sup>. This way, hash values act like a fingerprinting technique, which allows to compare files at two sites without actually transferring them.</p><p>However, with json volumes exceeding terabytes, even scanning the files to compute conventional hashes or fingerprints is already expensive. Indeed, the time required to scan a terabyte of json is about 25 minutes even for a modern high-speed 6Gbps drive. The situation is made worse by the fact that in many json centers disks are a shared resource. Consequently, a file synchronization method that is based on full file access can be intolerably slow for this setting.</p><p>There are ways of alleviating the problem by storing the precomputed hashes together with json files or tracking file changes on a system level. However, as of today, not many public json warehouses do it consistently. Moreover, biological json sets are often gathered by independent authorities, such as Array Express [<xref ref-type="bibr" rid="B7">7</xref>] and the NCBI Gene Expression Omnibus (GEO) [<xref ref-type="bibr" rid="B8">8</xref>]. As a result, these collections may contain a number of files with equal content that bear different filenames, or, contrarily, have equal filenames, but differ in content. If file fingerprinting is not supported by download servers, then any third party willing to download a consistent union of all the files has no other choice but to download all the files every time, even if many of them later turn out to be duplicates.</p><p>As a solution, we offer a new hashing algorithm, <italic>Probabilistic Fast File Fingerprinting (PFFF)</italic>, that computes file fingerprints by sampling only a few bytes from the file in a pseudorandom fashion. This makes on-demand hashing tractable. Most importantly, it can be applied over the network to quickly obtain hashes of files stored in remote third-party warehouses.</p><p>Although our approach might seem unorthodox, we demonstrate in the following sections that due to inherent variability in large-scale biological json, the risk of false positives due to sampling is negligible. In addition, we measure the performance of our approach on several storage and json access technologies. We discover that the performance gains due to sampling can vary considerably depending on the underlying technology. While PFFF outperforms conventional hashing for most file sizes, when used via web and on Flash storage, for hashing over the NFS network protocol, the benefits surface only with strict variability thresholds or at very large file sizes.</p></sec><sec sec-type="methods"><title>Methods</title><sec><title>Standard file fingerprinting algorithms</title><p>Hashing is a common method to speed up file comparison. A hash function compresses files into short digests <italic>(fingerprints) </italic>that are much easier to compare. If two fingerprints are different, the corresponding files are different, and whenever the fingerprints are the same, the files are the same, except for a negligibly small probability of a <italic>collision</italic>, i.e., two different files having the same fingerprint.</p><p>Hash functions can be divided into two classes: deterministic and probabilistic. A <italic>deterministic </italic>hash function is simply a fixed algorithm <italic>f </italic>that maps a file to its fingerprint:</p><p><disp-formula><mml:math id="M1" name="1471-2164-14-S2-S8-i14" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mo class="MathClass-rel">:</mml:mo><mml:mi mathvariant="script">M</mml:mi><mml:mo class="MathClass-rel">&#x02192;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo class="MathClass-open">{</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo class="MathClass-punc">,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo class="MathClass-close">}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>&#x02113;</mml:mi></mml:mrow></mml:msup><mml:mo class="MathClass-punc">,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="M2" name="1471-2164-14-S2-S8-i1" overflow="scroll"><mml:mi mathvariant="script">M</mml:mi><mml:mi>&#x000a0;</mml:mi></mml:math></inline-formula> is the space of all possible files of interest and &#x02113; is the length of the hash. Examples are the well-known MD5 [<xref ref-type="bibr" rid="B9">9</xref>] or SHA-256 [<xref ref-type="bibr" rid="B10">10</xref>] algorithms. As the number of possible fingerprints is finite and the number of possible files is, in principle, infinite, there may exist infinitely many files with colliding fingerprints. Thus there is no formal guarantee that for <italic>any </italic>given pair of files deterministic hashes would only collide with a negligible probability. Still, finding collisions for cryptographic hash functions such as SHA-256 is believed to be extremely difficult, and hence the probability of accidental collisions is negligible for all practical purposes [<xref ref-type="bibr" rid="B11">11</xref>].</p><p>A <italic>probabilistic </italic>hashing scheme is not a single hash function but rather a <italic>family </italic>of functions</p><p><disp-formula><mml:math id="M3" name="1471-2164-14-S2-S8-i15" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mo class="MathClass-rel">=</mml:mo><mml:mrow><mml:mo class="MathClass-open">{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-rel">:</mml:mo><mml:mi mathvariant="script">M</mml:mi><mml:mo class="MathClass-rel">&#x02192;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo class="MathClass-open">{</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo class="MathClass-punc">,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo class="MathClass-close">}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>&#x02113;</mml:mi></mml:mrow></mml:msup><mml:mo class="MathClass-rel">|</mml:mo><mml:mi>k</mml:mi><mml:mo class="MathClass-rel">&#x02208;</mml:mo><mml:mi mathvariant="script">K</mml:mi></mml:mrow><mml:mo class="MathClass-close">}</mml:mo></mml:mrow><mml:mo class="MathClass-punc">,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="M4" name="1471-2164-14-S2-S8-i2" overflow="scroll"><mml:mi mathvariant="script">K</mml:mi><mml:mi>&#x000a0;</mml:mi></mml:math></inline-formula> is the <italic>key space</italic>. Such a function family is useful in file fingerprinting if for any two fixed files <inline-formula><mml:math id="M5" name="1471-2164-14-S2-S8-i3" overflow="scroll"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-punc">,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-rel">&#x02208;</mml:mo><mml:mi mathvariant="script">M</mml:mi></mml:math></inline-formula>, and a <italic>randomly selected key k</italic>, the probability of a collision is bounded by a small number <italic>&#x003b5;<sub>c</sub></italic>:</p><p><disp-formula><mml:math id="M6" name="1471-2164-14-S2-S8-i4" overflow="scroll"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mspace class="tmspace" width="2.77695pt"/><mml:mrow><mml:mo class="MathClass-open">[</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo class="MathClass-rel">&#x02190;</mml:mo><mml:mi mathvariant="script">K</mml:mi><mml:mo class="MathClass-rel">:</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow><mml:mo class="MathClass-rel">=</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow></mml:mrow><mml:mo class="MathClass-close">]</mml:mo></mml:mrow><mml:mo class="MathClass-rel">&#x02264;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mi>.</mml:mi></mml:mrow></mml:math></disp-formula></p><p>Function families that satisfy this condition are usually referred to as <italic>&#x003b5;</italic><sub>c</sub>-<italic>almost universal</italic>. Efficient algorithms for such <italic>universal hash functions </italic>have been known for decades. See [<xref ref-type="bibr" rid="B11">11</xref>,<xref ref-type="bibr" rid="B12">12</xref>] for further details.</p></sec><sec><title>Inherent variability of biological json</title><p>Due to long research history, standard file fingerprinting methods have reached perfection and it is extremely difficult to outperform them if no additional assumptions can be made about the json. However, biological json collections are quite specific. In particular, the situation when two large json files meaningfully differ in only a few bits is very unlikely in practice. Empirical examination of large repositories of biological json confirms that whenever two differently named files coincide in more than 20% of bytes, they are either misformattings of the same json, or may be treated as equivalent for the purposes of most large-scale analyses. For compressed json files the similarity bound is as large as 90%. See Results for further details.</p><p>This observation can be postulated as the <italic>&#x003b4;-variability assumption</italic>. Assume that each file is represented as a sequence of blocks, e.g. bytes. Then a json collection satisfies <italic>&#x003b4;</italic>-variability assumption if any two distinct files of the same length <italic>x </italic>= (<italic>x</italic><sub>1</sub>, . . . , <italic>x<sub>m</sub></italic>) and <italic>y </italic>= (<italic>y</italic><sub>1</sub>, . . . , <italic>y<sub>m</sub></italic>) differ at least in <italic>&#x003b4;</italic>-fraction of the blocks:</p><p><disp-formula><mml:math id="M7" name="1471-2164-14-S2-S8-i5" overflow="scroll"><mml:mrow><mml:mo class="MathClass-rel">|</mml:mo><mml:mrow><mml:mo class="MathClass-open">{</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo class="MathClass-rel">:</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-rel">&#x02260;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo class="MathClass-close">}</mml:mo></mml:mrow><mml:mo class="MathClass-rel">|</mml:mo><mml:mspace class="tmspace" width="2.77695pt"/><mml:mo class="MathClass-rel">&#x02265;</mml:mo><mml:mspace class="tmspace" width="2.77695pt"/><mml:mi>&#x003b4;</mml:mi><mml:mi>m</mml:mi><mml:mi>.</mml:mi></mml:mrow></mml:math></disp-formula></p></sec><sec><title>New file fingerprinting method</title><p>Explicit use of json variability is the key to more efficient hashing. Let <italic>x </italic>and <italic>y </italic>be two files of length <italic>m </italic>satisfying the <italic>&#x003b4;</italic>-variability assumption. Now, if we sample uniformly with replacement &#x02113; indices <italic>i</italic><sub>1</sub>, . . . , i<sub>&#x02113; </sub>&#x02208; {1 , . . . , <italic>m</italic>}, then the probability that all the corresponding blocks in two files coincide (a <italic>sampling collision</italic>) is bounded from above:</p><p><disp-formula><mml:math id="M8" name="1471-2164-14-S2-S8-i16" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">s</mml:mtext></mml:mstyle></mml:mrow></mml:msub><mml:mo class="MathClass-rel">=</mml:mo><mml:mtext>Pr</mml:mtext><mml:mspace class="tmspace" width="2.77695pt"/><mml:mrow><mml:mo class="MathClass-open">[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo class="MathClass-rel">=</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo class="MathClass-punc">,</mml:mo><mml:mspace class="tmspace" width="2.77695pt"/><mml:mi>.</mml:mi><mml:mspace class="tmspace" width="2.77695pt"/><mml:mi>.</mml:mi><mml:mspace class="tmspace" width="2.77695pt"/><mml:mi>.</mml:mi><mml:mspace class="tmspace" width="2.77695pt"/><mml:mo class="MathClass-punc">,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x02113;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo class="MathClass-rel">=</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x02113;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo class="MathClass-close">]</mml:mo></mml:mrow><mml:mo class="MathClass-rel">&#x02264;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo class="MathClass-bin">-</mml:mo><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>&#x02113;</mml:mi></mml:mrow></mml:msup><mml:mi>.</mml:mi></mml:mrow></mml:math></disp-formula></p><p>More generally, for any collection of <italic>n </italic>distinct files that satisfies the <italic>&#x003b4;</italic>-variability assumption, the probability that a sample of &#x02113; blocks coincides for at least one pair of files is bounded by:</p><p><disp-formula><mml:math id="M9" name="1471-2164-14-S2-S8-i6" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">fail</mml:mtext></mml:mstyle></mml:mrow></mml:msub><mml:mo class="MathClass-rel">=</mml:mo><mml:mtext>Pr</mml:mtext><mml:mspace class="tmspace" width="2.77695pt"/><mml:mrow><mml:mo class="MathClass-open">[</mml:mo><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">Some</mml:mtext></mml:mstyle><mml:mo class="MathClass-bin">-</mml:mo><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">collision</mml:mtext></mml:mstyle></mml:mrow><mml:mo class="MathClass-close">]</mml:mo></mml:mrow><mml:mo class="MathClass-rel">&#x02264;</mml:mo><mml:mn>0</mml:mn><mml:mi>.</mml:mi><mml:mn>5</mml:mn><mml:mi>n</mml:mi><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo class="MathClass-bin">-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">s</mml:mtext></mml:mstyle></mml:mrow></mml:msub><mml:mi>.</mml:mi></mml:mrow></mml:math></disp-formula></p><p>For instance, if the variability threshold is <italic>&#x003b4; </italic>= 0.5 and we sample 103 random blocks, a sampling collision for a single pair of files may emerge with probability <italic>&#x003b5;</italic><sub>s </sub>&#x02264; 2<sup>-103</sup>. For a set of 10<sup>6 </sup>files, some collision occurs with probability <italic>&#x003b5;</italic><sub>fail </sub>&#x02264; 5 &#x000b7; 10<sup>-20</sup>, which is comparable to the probability of a hardware failure.</p><p>In general, any desired upper bound for collision probability <italic>&#x003b5;</italic><sub>fail </sub>can be achieved with</p><p><disp-formula id="bmcM1"><label>(1)</label><mml:math id="M10" name="1471-2164-14-S2-S8-i17" overflow="scroll"><mml:mrow><mml:mi>&#x02113;</mml:mi><mml:mo class="MathClass-rel">&#x02265;</mml:mo><mml:mfrac><mml:mrow><mml:mtext>log</mml:mtext><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo class="MathClass-bin">/</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">fail</mml:mtext></mml:mstyle></mml:mrow></mml:msub></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow><mml:mo class="MathClass-bin">+</mml:mo><mml:mn>2</mml:mn><mml:mtext>log</mml:mtext><mml:mspace class="thinspace" width="0.3em"/><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo class="MathClass-bin">-</mml:mo><mml:mtext>log</mml:mtext><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo class="MathClass-bin">-</mml:mo><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>samples. Observe that &#x02113; does not depend on the file size. Also note that &#x02113; scales logarithmically with 1/<italic>&#x003b5;</italic><sub>fail </sub>and <italic>n</italic>, which means that improvements to the desired failure probability <italic>&#x003b5;</italic><sub>fail </sub>and the number of files <italic>n </italic>only moderately increase the required sample size.</p><p>Samples <inline-formula><mml:math id="M11" name="1471-2164-14-S2-S8-i18" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo class="MathClass-op"> ^</mml:mo></mml:mover><mml:mo class="MathClass-rel">=</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x02113;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M12" name="1471-2164-14-S2-S8-i19" overflow="scroll"><mml:mrow><mml:mi>&#x00177;</mml:mi><mml:mo class="MathClass-rel">=</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x02113;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> do not have to be compared directly. Instead, we can further compress them by some universal hashing scheme <inline-formula><mml:math id="M13" name="1471-2164-14-S2-S8-i7" overflow="scroll"><mml:mi mathvariant="script">F</mml:mi><mml:mo class="MathClass-rel">=</mml:mo><mml:mrow><mml:mo class="MathClass-open">{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo class="MathClass-close">}</mml:mo></mml:mrow></mml:math></inline-formula> and compare <inline-formula><mml:math id="M14" name="1471-2164-14-S2-S8-i8" overflow="scroll"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo class="MathClass-op"> ^</mml:mo></mml:mover></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M15" name="1471-2164-14-S2-S8-i9" overflow="scroll"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mi>&#x00177;</mml:mi></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow></mml:math></inline-formula>. As a result, the probability of collisions increases, because with some probability <inline-formula><mml:math id="M16" name="1471-2164-14-S2-S8-i10" overflow="scroll"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo class="MathClass-op"> ^</mml:mo></mml:mover></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow><mml:mo class="MathClass-rel">=</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mi>&#x00177;</mml:mi></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow></mml:math></inline-formula> even if <inline-formula><mml:math id="M17" name="1471-2164-14-S2-S8-i11" overflow="scroll"><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo class="MathClass-op"> ^</mml:mo></mml:mover><mml:mo class="MathClass-rel">&#x02260;</mml:mo><mml:mi>&#x00177;</mml:mi></mml:math></inline-formula>. However, if <inline-formula><mml:math id="M18" name="1471-2164-14-S2-S8-i12" overflow="scroll"><mml:mi mathvariant="script">F</mml:mi><mml:mi>&#x000a0;</mml:mi></mml:math></inline-formula> is <italic>&#x003b5;</italic><sub>c</sub>-almost universal, this probability is bounded by <italic>&#x003b5;</italic><sub>c </sub>and consequently the overall probability of a single collision is only marginally increased:</p><p><disp-formula><mml:math id="M19" name="1471-2164-14-S2-S8-i13" overflow="scroll"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mspace class="tmspace" width="2.77695pt"/><mml:mrow><mml:mo class="MathClass-open">[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo class="MathClass-op"> ^</mml:mo></mml:mover></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow><mml:mo class="MathClass-rel">=</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mi>&#x00177;</mml:mi></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow></mml:mrow><mml:mo class="MathClass-close">]</mml:mo></mml:mrow><mml:mo class="MathClass-rel">&#x02264;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-bin">+</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mi>.</mml:mi></mml:mrow></mml:math></disp-formula></p><p>Finally, note that all random bits needed to generate indices <italic>i</italic><sub>1</sub>, . . . , <italic>i</italic><sub>&#x02113; </sub>and the key <italic>k </italic>can be replaced with the output of a pseudorandom number generator. In practice, any sufficiently complex pseudorandom generator will be adequate. We choose to use the fast and currently widely popular Mersenne twister algorithm [<xref ref-type="bibr" rid="B13">13</xref>] in our implementation.</p></sec></sec><sec sec-type="results"><title>Results</title><sec><title>Variability in biological json</title><p>The cornerstone of our new hashing algorithm is the assumption that any two files in a biological json collection can either be treated as identical or necessarily differ in at least a <italic>&#x003b4;</italic>-fraction of places. To study to what extent this variability assumption holds for biological json, we tested several kinds of common biological datasets, including both DNA sequence and tabular numeric json, both in compressed and uncompressed forms (Table <xref ref-type="table" rid="T1">1</xref>).</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Variability in biological json</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">Description</th><th align="center">File type</th><th align="center">Number of files</th><th align="center">Total size (in GB)</th><th align="center" colspan="2">File size (in MB)</th><th align="center">
<italic>&#x003b4;</italic>
</th></tr><tr><th/><th/><th/><th/><th/><th colspan="2"><hr/></th><th/></tr><tr><th/><th/><th/><th/><th/><th align="center">Min</th><th align="center">Max</th><th/></tr></thead><tbody><tr><td align="left">E61/dat</td><td align="left">Ensembl v61 genome annotation (DAT) and DNA sequence (FASTA) files in both compressed (gzip) and uncompressed forms.</td><td align="left">dat</td><td align="left">5544</td><td align="left">169.57</td><td align="left">5.04</td><td align="left">1385.14</td><td align="left">0.782</td></tr><tr><td colspan="1"><hr/></td><td/><td colspan="6"><hr/></td></tr><tr><td align="left">E61/dat.gz</td><td/><td align="left">dat.gz</td><td align="left">5544</td><td align="left">42.92</td><td align="left">1.02</td><td align="left">400.21</td><td align="left">0.996</td></tr><tr><td colspan="1"><hr/></td><td/><td colspan="6"><hr/></td></tr><tr><td align="left">E61/fa</td><td/><td align="left">fa</td><td align="left">1484</td><td align="left">498.51</td><td align="left">3.47</td><td align="left">13306.96</td><td align="left">0.015</td></tr><tr><td colspan="1"><hr/></td><td/><td colspan="6"><hr/></td></tr><tr><td align="left">E61/fa.gz</td><td/><td align="left">fa.gz</td><td align="left">1484</td><td align="left">95.25</td><td align="left">1.0</td><td align="left">973.15</td><td align="left">0.594</td></tr><tr><td colspan="8"><hr/></td></tr><tr><td align="left">GPL570/cel</td><td align="left">Microarray files for the HG U133 Plus chip from GEO (all files of GPL570 platform as of 03.2011). Affymetrix CEL and CHP format files, in compressed (gzip) and uncompressed form.</td><td align="left">cel</td><td align="left">59892</td><td align="left">1022.29</td><td align="left">1.92</td><td align="left">173.27</td><td align="left">0.000</td></tr><tr><td colspan="1"><hr/></td><td/><td colspan="6"><hr/></td></tr><tr><td align="left">GPL570/cel.gz</td><td/><td align="left">cel.gz</td><td align="left">59892</td><td align="left">330.09</td><td align="left">1.13</td><td align="left">48.84</td><td align="left">0.000</td></tr><tr><td colspan="1"><hr/></td><td/><td colspan="6"><hr/></td></tr><tr><td align="left">GPL570/chp</td><td/><td align="left">chp</td><td align="left">2535</td><td align="left">63.30</td><td align="left">1.67</td><td align="left">36.50</td><td align="left">0.209</td></tr><tr><td colspan="1"><hr/></td><td/><td colspan="6"><hr/></td></tr><tr><td align="left">GPL570/ch.gz</td><td/><td align="left">chp.gz</td><td align="left">2535</td><td align="left">26.36</td><td align="left">1.02</td><td align="left">23.05</td><td align="left">0.995</td></tr><tr><td colspan="8"><hr/></td></tr><tr><td align="left">BioC2.7/BSGenome</td><td align="left">Raw DNA sequence from the Bioconductor package BSGenome, in compressed and uncompressed forms</td><td align="left">rda</td><td align="left">513</td><td align="left">8.45</td><td align="left">1.00</td><td align="left">117.17</td><td align="left">0.981</td></tr><tr><td colspan="1"><hr/></td><td/><td colspan="6"><hr/></td></tr><tr><td align="left">BioC2.7/BSGenome/u</td><td/><td align="left">un-packed</td><td align="left">513</td><td align="left">32.41</td><td align="left">1.62</td><td align="left">447.40</td><td align="left">0.000</td></tr><tr><td colspan="8"><hr/></td></tr><tr><td align="left">YaleTFBS/bedGraph4</td><td align="left">Raw ChIP-seq json from the YaleTFBS dataset of the ENCODE project. Four different file types, both in compressed and uncompressed forms.</td><td align="left">bed-Graph4</td><td align="left">171</td><td align="left">139.91</td><td align="left">216.73</td><td align="left">2447.62</td><td align="left">0.924</td></tr><tr><td colspan="1"><hr/></td><td/><td colspan="6"><hr/></td></tr><tr><td align="left">YaleTFBS/bedGraph4.gz</td><td/><td align="left">bed-Graph4.gz</td><td align="left">171</td><td align="left">31.45</td><td align="left">52.89</td><td align="left">551.80</td><td align="left">0.996</td></tr><tr><td colspan="1"><hr/></td><td/><td colspan="6"><hr/></td></tr><tr><td align="left">YaleTFBS/fastq</td><td/><td align="left">fastq</td><td align="left">388</td><td align="left">541.99</td><td align="left">199.25</td><td align="left">4469.89</td><td align="left">0.919</td></tr><tr><td colspan="1"><hr/></td><td/><td colspan="6"><hr/></td></tr><tr><td align="left">YaleTFBS/fastq.gz</td><td/><td align="left">fastq.gz</td><td align="left">388</td><td align="left">160.75</td><td align="left">49.55</td><td align="left">1564.84</td><td align="left">0.996</td></tr><tr><td colspan="1"><hr/></td><td/><td colspan="6"><hr/></td></tr><tr><td align="left">YaleTFBS/tagAlign</td><td/><td align="left">tagAlign</td><td align="left">520</td><td align="left">279.45</td><td align="left">79.95</td><td align="left">2357.32</td><td align="left">0.544</td></tr><tr><td colspan="1"><hr/></td><td/><td colspan="6"><hr/></td></tr><tr><td align="left">YaleTFBS/tagAlign.gz</td><td/><td align="left">tag-Align.gz</td><td align="left">520</td><td align="left">96.70</td><td align="left">27.86</td><td align="left">815.63</td><td align="left">0.994</td></tr><tr><td colspan="1"><hr/></td><td/><td colspan="6"><hr/></td></tr><tr><td align="left">YaleTFBS/wig</td><td/><td align="left">wig</td><td align="left">33</td><td align="left">10.66</td><td align="left">188.92</td><td align="left">693.66</td><td align="left">0.912</td></tr><tr><td colspan="1"><hr/></td><td/><td colspan="6"><hr/></td></tr><tr><td align="left">YaleTFBS/wig.gz</td><td/><td align="left">wig.gz</td><td align="left">33</td><td align="left">3.27</td><td align="left">59.76</td><td align="left">207.93</td><td align="left">0.996</td></tr></tbody></table><table-wrap-foot><p>Measurements of <italic>&#x003b4;</italic>-variability in several biological datasets. Exact description of the experiment is available in the Supplementary material online [<xref ref-type="bibr" rid="B14">14</xref>].</p></table-wrap-foot></table-wrap><p>For each dataset we found the byte-wise most similar pair of files, ignoring misnamings and differences in file sizes. The reported <italic>&#x003b4; </italic>is the variability metric for this best pair (i.e. the proportion of pairwise different bytes). Exact details of this experiment as well as the json files are provided in the Supplementary Text online [<xref ref-type="bibr" rid="B14">14</xref>].</p><p>From the results we see that for most datasets, <italic>&#x003b4; </italic>is at least 0.2, and for the majority of compressed datasets <italic>&#x003b4; </italic>is at least 0.9. There seem to be some notable exceptions, however: the E61/fa, GPL570/cel, GPL570/cel.gz, BioC2.7/BSGenome/u datasets have at least a single pair of highly similar files. To better understand the implications of this result we examined the corresponding pairs manually (Table <xref ref-type="table" rid="T2">2</xref>). Manual examination showed that for the non-DNA json used in our experiments, all cases of similar file pairs are instances of misformattings of the same raw json, which are irrelevant from the point of view of json analysis. In the case of DNA json, there were examples of a few pairs of DNA sequences which, when unpacked, are highly similar, as they correspond to different haplotypes or genome assemblies of the same organism.</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p>Detailed inspection of similar file pairs</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset </th><th align="left">File pair and remarks </th><th align="left">File sizes (in MB) </th><th align="center">&#x003b4; </th></tr></thead><tbody><tr><td align="left">E61/fa</td><td align="left">Homo_sapiens.GRCh37.61.dna_rm.chromosome.HSCHR6_MHC_SSTO.fa</td><td align="left">166.04</td><td align="center">0.015</td></tr><tr><td/><td align="left"><break/>Homo_sapiens.GRCh37.61.dna_rm.chromosome.HSCHR6_MHC_MANN.fa</td><td align="left">166.06</td><td/></tr><tr><td/><td align="left">These are two alternative haplotype "patch" files for the same chromosome locus. The dataset contains 11 other examples of similar file pairs with <italic>&#x003b4; </italic>&#x0003c; 0.06 (when unpacked). All are related to the alternative haplotypes for the MHC locus. The next most similar pair of files has <italic>&#x003b4; </italic>&#x0003e; 0.8.</td><td/><td/></tr><tr><td colspan="4"><hr/></td></tr><tr><td align="left">GPL570/cel</td><td align="left">GSM405175.CEL</td><td align="left">12.93</td><td align="center">8e-6</td></tr><tr><td align="left"/><td align="left">GSM341406.CEL</td><td align="left">12.93</td><td/></tr><tr><td/><td align="left">The second file differs from the first by a single Affymetrix probe measurement. According to GEO metadata the two files are simply different packagings of the same experimental json by two researchers. The GEO570 dataset contains 9 other examples of similar file pairs with <italic>&#x003b4; </italic>&#x0003c; 0.002. The next most similar pair of files has <italic>&#x003b4; </italic>&#x0003e; 0.3.</td><td/><td/></tr><tr><td colspan="4"><hr/></td></tr><tr><td align="left">GPL570/cel.gz</td><td align="left">GSM405175.CEL.gz</td><td align="left">4.31</td><td align="left">6e-4</td></tr><tr><td/><td align="left">GSM341406.CEL.gz</td><td align="left">4.31</td><td/></tr><tr><td/><td align="left">A gzip-compressed version of the pair above. Same remarks apply. The most similar pair of actually different datafiles has <italic>&#x003b4; </italic>&#x0003e; 0.9.</td><td/><td/></tr><tr><td colspan="4"><hr/></td></tr><tr><td align="left">BioC2.7/B SGenome/u</td><td align="left">BSgenome.Athaliana.TAIR.01222004/extdata/chr1.rda</td><td align="left">29.04</td><td align="left">2e-4</td></tr><tr><td/><td align="left">BSgenome.Athaliana.TAIR.04232008/extdata/chr1.rda</td><td align="left">29.04</td><td/></tr><tr><td/><td align="left">Consequtive versions of A.thaliana reference genome. The next most similar file pair in this dataset has <italic>&#x003b4; </italic>&#x0003e; 0.5. Note that the compressed versions of the same files have <italic>&#x003b4; </italic>&#x0003e; 0.9.</td><td/><td/></tr></tbody></table><table-wrap-foot><p>The table lists the suspiciously similar pairs of files from the studied datasets.</p></table-wrap-foot></table-wrap><p>Those observations largely confirm the assumption of the wide applicability of PFFF hashing in the context of biological json. Care should be taken in the case of datasets containing <italic>uncompressed genome sequences </italic>with minor variations, when those variations <italic>are key to the analysis</italic>. In such situations it makes more sense to rely on consistent file naming, conventional hashing, or, best of all, compressed representation of the variations. As we can see in Table <xref ref-type="table" rid="T1">1</xref> even plain gzip compression is sufficient to ensure high <italic>&#x003b4;</italic>-variability. Based on our measurements, we suggest <italic>&#x003b4; </italic>= 0.9 as a reasonable choice for datasets consisting of compressed files and <italic>&#x003b4; </italic>= 0.2 as a safe choice for general-purpose PFFF-hashing. Substituting <italic>&#x003b5;</italic><sub>fail </sub>= 2<sup>-64 </sup>and <italic>n </italic>= 10<sup>6 </sup>into Equation (1) we obtain that for <italic>&#x003b4; </italic>= 0.9, a sample size of just &#x02113; = 32 blocks guarantees negligible probability of collisions. For <italic>&#x003b4; </italic>= 0.2 the guarantees are satisfied by &#x02113; = 325.</p></sec><sec><title>Algorithm performance</title><p>To compare PFFF to conventional hashing we compared the runtime of our algorithm to the (still) popular MD5 hashing algorithm in a variety of settings: hashing over HTTP and NFS network protocols, hashing on a local SSD (Flash) drive and on a portable USB hard disk. We should note that the choice of MD5 as the baseline is fairly arbitrary, as the hashing time is heavily dominated by I/O rather than actual hash value calculations.</p><p>In our experiments we considered the values of &#x02113; = 32 and &#x02113; = 325, corresponding to the two common situations highlighted in the previous section. Results are presented in Figure <xref ref-type="fig" rid="F1">1</xref> and in the Supplementary Text [<xref ref-type="bibr" rid="B14">14</xref>]. Several interesting remarks are in order.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Comparison of PFFF to conventional hashing</bold>. The plots demonstrate time for hashing a single file of a given size by MD5 and by PFFF. Note that axis scales on the four plots are different.</p></caption><graphic xlink:href="1471-2164-14-S2-S8-1"/></fig><sec><title>Performance of hashing via network</title><p>As one might expect, use of PFFF over HTTP outperforms conventional MD5 hashing for any file size (although for smaller file sizes the benefits are minor). The reason lies in the fact that HTTP protocol supports <italic>range queries </italic>[<xref ref-type="bibr" rid="B15">15</xref>]. This allows the client to make a single request demanding specifically those bytes which are necessary to compute the PFFF hash. This is much more efficient than a complete file download performed in the case of conventional hashing.</p><p>Another network protocol, NFS, however, demonstrates a different result. Contrary to HTTP, in case of NFS each of the samples has to be queried using a separate request. As a result, network latency starts dominating the processing time and in the case of &#x02113; = 325, PFFF hashing is actually <italic>slower </italic>than straightforward file scan for file sizes up to about 500MB (50MB for &#x02113; = 32). Of course, as file size grows larger, the timing of MD5 hashing continues to increase linearly while PFFF time stays constant, but for practical purposes of contemporary json analysis we must conclude that PFFF is not useful over NFS, not at least with the "safe" &#x02113; = 325 setting.</p></sec><sec><title>Performance on rotational and solid-state media</title><p>Random access to json on hard disk (HDD) and solid-state (SSD) drives does not come for free, as we can observe in the two rightmost panels of Figure <xref ref-type="fig" rid="F1">1</xref>. For file sizes up to about 10MB, timings of 325-sample PFFF are no better than that of a complete file scan. For larger files, PFFF becomes beneficial, but the situations in the case of SSD and HDD storage differ slightly. For SSD storage, the timing characteristic of PFFF flattens out fairly quickly (e.g. after reaching 0.3 seconds at 10MB for &#x02113; = 325). For a rotational hard drive, however, timing continues to grow slowly with file size until for &#x02113; = 325 it plateaus somewhere around 2.5 seconds for file sizes of 200MB or larger.</p><p>The main reason for this effect lies in the operation of a rotational drive. On such drives, json is accessed via continuously rotating magnetic heads reading json off <italic>tracks</italic>. For smaller files, multiple PFFF samples can often happen to be located on the same track and thus read within a single revolution of the disk. As file size becomes large enough, however, each byte request will typically require a track switch followed by a seek operation. Such an operation requires, on average, half a revolution. As the time per revolution for a 5400rpm drive is approximately 11ms, randomly accessing 325 samples requires about 1.8 seconds. Our actual measured time is just slightly larger as it also includes file system access and USB communication overhead.</p><p>In general, assuming that a typical rotational hard drive can read as much as 0.5M of json in a single revolution, we can estimate that for sufficiently large files, an &#x02113;-sample PFFF hash computation requires approximately as much time as a full scan of a 0.25&#x02113;-megabyte file.</p><p>Note that we observe the same effect in our HTTP experiment for &#x02113; = 325, due to the fact that the HTTP server was also using a HDD backend.</p><p>This observation limits the usefulness of PFFF for rotational media to some extent. The situation may be alleviated by using a small number of large blocks instead of a large number of single bytes in PFFF hashing. In fact, our measurements confirm that among all the files in our datasets except for uncompressed haplotype variations, no two distinct files (misformattings not taken into account) share even a single common block of size 0.5M, which means that <italic>&#x003b4; </italic>for such a large block size is close to 1.</p></sec></sec><sec><title>Application in duplicate detection</title><p>An interesting alternative application for PFFF is fast detection of unwanted duplicates or format errors in large scientific json warehouses. Intuitively, if two distinct files yield the same PFFF hash value then they are either identical or highly similar and thus deserve further investigation.</p><p>More formally, we can regard duplicate detection as a classical statistical hypothesis testing problem, where the null hypothesis states that all the <italic>n </italic>files in a json warehouse satisfy the <italic>&#x003b4;</italic>-variability condition. We can now fix <italic>&#x003b5;</italic><sub>fail </sub>= 0.05 (a significance level threshold commonly used in hypothesis testing), compute the corresponding &#x02113; value using Equation (1) and apply PFFF with this value of &#x02113; to all files in the warehouse. Any hash collisions can now be regarded as evidence, rejecting the null hypothesis.</p><p>To provide a more specific example, consider the GPL570/cel.gz dataset from the GEO warehouse, listed in Table <xref ref-type="table" rid="T1">1</xref>. Considering that it consists of gzip-compressed files we can postulate a true <italic>&#x003b4;</italic>-variability between meaningfully distinct files of at least 0.9. Substituting <italic>&#x003b4; </italic>= 0.9, <italic>n </italic>= 59892, <italic>&#x003b5;</italic><sub>fail </sub>= 0.05 into Equation (1) we obtain &#x02113; &#x02248; 11. Having applied PFFF with &#x02113; = 11 on the files of the dataset we discovered 8165 groups of equal or equivalent files, the largest of them comprising 10 files. The total volume of redundant files was more than 54 gigabytes, unnecessarily hogging more than 16% of the dataset space!</p></sec><sec><title>Implementation details</title><p>The implementation of our algorithm is available as an open-source tool <bold>pfff </bold>available for download at <ext-link ext-link-type="uri" xlink:href="http://biit.cs.ut.ee/pfff">http://biit.cs.ut.ee/pfff</ext-link>. Besides the basic probabilistic hash function, the tool provides several additional convenience features, such as the ability to include file headers and file size in the hash. The whole package is available under the open source BSD License, both as as stand alone tool and a C library.</p></sec></sec><sec sec-type="discussion"><title>Discussion</title><p>The main requisite for PFFF is that the json to be analysed must satisfy the variability assumption. Biological json sets are likely to satisfy this requirement for two reasons. First, there is inherent variability in the biological systems - no two cells are identical. Secondly, even if the measurements are taken from the same cell at the same time point, the complicated measurement procedures result in sufficient amount of measurement errors. It is highly unlikely to obtain <italic>exactly </italic>the same results in two different experiments. Nonetheless, situations are possible, where the level of variability is rather low. For instance, raw sequencing json of individuals has low variance, as only 2-5% of base pairs differ from the reference sequence. In such cases, it is normally more advantageous to store and transfer differences (SNP's, insertions and deletions) to save the storage space and network load. Such compression increases variability and enables the application of PFFF. Other file compression techniques (e.g. gzip) have roughly the same effect, as they remove repeating patterns that are shared over files.</p><p>In addition, PFFF's reliability may be boosted to near certainty for all practical purposes by including into the fingerprint the size of the file and the first megabyte or so of json. Indeed, in most file formats the <italic>header </italic>usually contains most of the important identifying information.</p><p>In our experiments we discovered that despite the theoretical guarantees of constant runtime for PFFF, several practical aspects, such as network latency, rotational operation of hard disks and sequential access optimizations implemented on the operating system level (e.g. json prefetching), may limit the advantages of the approach over conventional hashing. We observed that the benefits of PFFF hashing are strongest when json must be accessed over HTTP or when SSD storage is involved. In other contexts, application of PFFF requires further assumptions in order to provide significant advantages.</p><p>In particular, for very large files (with sizes approaching and exceeding a gigabyte) PFFF is nearly always meaningful. Alternatively, higher <italic>&#x003b4;</italic>-variability in the json allows to reduce the &#x02113; parameter, drastically reducing the number of requests. As we noted, <italic>&#x003b4; </italic>= 0.9 and the corresponding &#x02113; = 32 are meaningful settings for collections of compressed files.</p><p>Higher <italic>&#x003b4;</italic>-variability can also often be assumed by increasing block size. Moreover, for rotational storage, meaningful block sizes are anyway on the order 0.5 megabytes, as this is the the chunk of json read by the disk during a single revolution.</p><p>Finally, note that the need for our method would be greatly diminished if the prominent warehouses agreed on publishing deterministic hashes together with the json files. Unfortunately, it may still take a few years before such agreement emerges. After that, the PFFF hash could still provide a useful fallback mechanism.</p></sec><sec sec-type="conclusions"><title>Conclusion</title><p>We have proposed a specially tailored method for fingerprinting biological json files, which can significantly reduce consumption of critical resources in several common usage patterns of big json analysis workflows. Our PFFF algorithm allows for rapid checking of equivalence of large files acquired from biological samples with little computational overhead, thus possibly reducing the number of files read and transferred between and within json centers.</p><p>The application of PFFF is not limited to biological json. Indeed, probabilistic fingerprinting applies to any json with high variability. This includes, in particular, json that contains noisy measurements, such as scientific json in astronomy or particle physics, as well as sound and video files.</p></sec><sec><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec><title>Authors' contributions</title><p>PP conceived the idea of the approach and drafted the manuscript. SL developed the idea theoretically and helped draft the manuscript. KT developed the idea theoretically, implemented the algorithm, performed experiments, prepared figures and supplementaries, and wrote the final manuscript. GS and JV participated in the coordination of the study and helped draft the manuscript. All authors read and approved the final manuscript.</p></sec></body><back><sec><title>Acknowledgements</title><p>Authors would like to acknowledge Marti Taremaa for invaluable advice as well as administration of the server-side hardware used in the experiments.</p><p>Research was funded by Estonian target funding SF0180008s12, Complexity-Net CIESCI, ERF CoE EXCS, and University of Tartu (SP1GVARENG).</p></sec><sec><title>Declarations</title><p>The publication costs for this article were funded by the European Regional Development Fund through the Estonian Center of Excellence in Computer Science, EXCS.</p><p>This article has been published as part of <italic>BMC Genomics </italic>Volume 14 Supplement 2, 2013: Selected articles from ISCB-Asia 2012. The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/bmcgenomics/supplements/14/S2">http://www.biomedcentral.com/bmcgenomics/supplements/14/S2</ext-link>.</p></sec><ref-list><ref id="B1"><mixed-citation publication-type="journal"><name><surname>Doctorow</surname><given-names>C</given-names></name><article-title>Big json: Welcome to the petacentre</article-title><source>Nature</source><year>2008</year><volume>455</volume><issue>7209</issue><fpage>16</fpage><lpage>21</lpage><ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/455016a">http://dx.doi.org/10.1038/455016a</ext-link><pub-id pub-id-type="doi">10.1038/455016a</pub-id><pub-id pub-id-type="pmid">18769411</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><name><surname>Richter</surname><given-names>BG</given-names></name><name><surname>Sexton</surname><given-names>DP</given-names></name><article-title>Managing and analyzing next-generation sequence json</article-title><source>PLoS Comput Biol</source><year>2009</year><volume>5</volume><issue>6</issue><fpage>e1000369</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000369</pub-id><pub-id pub-id-type="pmid">19557125</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="book"><name><surname>Tridgell</surname><given-names>A</given-names></name><article-title>Efficient algorithms for sorting and synchronization</article-title><source>PhD thesis</source><year>1999</year><publisher-name>The Australian National University</publisher-name><ext-link ext-link-type="uri" xlink:href="http://www.samba.org/~tridge/phd_thesis.pdf">http://www.samba.org/~tridge/phd_thesis.pdf</ext-link></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="book"><name><surname>Carter</surname><given-names>LJ</given-names></name><name><surname>Wegman</surname><given-names>MN</given-names></name><article-title>Universal classes of hash functions</article-title><source>Proceedings of the ninth annual ACM symposium on Theory of computing</source><year>1977</year><publisher-name>New York, NY, USA: ACM</publisher-name><fpage>106</fpage><lpage>112</lpage><ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1145/800105.803400">http://dx.doi.org/10.1145/800105.803400</ext-link></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><name><surname>Trachtenberg</surname><given-names>A</given-names></name><name><surname>Starobinski</surname><given-names>D</given-names></name><name><surname>Agarwal</surname><given-names>S</given-names></name><article-title>Fast PDA synchronization using characteristic polynomial interpolation</article-title><source>INFOCOM</source><year>2002</year><volume>3</volume><fpage>1510</fpage><lpage>1519</lpage><ext-link ext-link-type="uri" xlink:href="http://people.bu.edu/staro/infocom02pda.pdf">http://people.bu.edu/staro/infocom02pda.pdf</ext-link></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><name><surname>Minsky</surname><given-names>Y</given-names></name><name><surname>Trachtenberg</surname><given-names>A</given-names></name><name><surname>Zippel</surname><given-names>R</given-names></name><article-title>Set reconciliation with nearly optimal communication complexity</article-title><source>IEEE Transactions on Information Theory</source><year>2003</year><volume>49</volume><issue>9</issue><fpage>2213</fpage><lpage>2218</lpage><pub-id pub-id-type="doi">10.1109/TIT.2003.815784</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><name><surname>Parkinson</surname><given-names>H</given-names></name><name><surname>Kapushesky</surname><given-names>M</given-names></name><name><surname>Shojatalab</surname><given-names>M</given-names></name><name><surname>Abeygunawardena</surname><given-names>N</given-names></name><name><surname>Coulson</surname><given-names>R</given-names></name><name><surname>Farne</surname><given-names>A</given-names></name><name><surname>Holloway</surname><given-names>E</given-names></name><name><surname>Kolesnykov</surname><given-names>N</given-names></name><name><surname>Lilja</surname><given-names>P</given-names></name><name><surname>Lukk</surname><given-names>M</given-names></name><name><surname>Mani</surname><given-names>R</given-names></name><name><surname>Rayner</surname><given-names>T</given-names></name><name><surname>Sharma</surname><given-names>A</given-names></name><name><surname>William</surname><given-names>E</given-names></name><name><surname>Sarkans</surname><given-names>U</given-names></name><name><surname>Brazma</surname><given-names>A</given-names></name><article-title>ArrayExpress-a public database of microarray experiments and gene expression profiles</article-title><source>Nucleic Acids Res</source><year>2007</year><volume>35</volume><issue>Database</issue><fpage>D747</fpage><lpage>D750</lpage><pub-id pub-id-type="doi">10.1093/nar/gkl995</pub-id><pub-id pub-id-type="pmid">17132828</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><name><surname>Barrett</surname><given-names>T</given-names></name><name><surname>Troup</surname><given-names>DB</given-names></name><name><surname>Wilhite</surname><given-names>SE</given-names></name><name><surname>Ledoux</surname><given-names>P</given-names></name><name><surname>Evangelista</surname><given-names>C</given-names></name><name><surname>Kim</surname><given-names>IF</given-names></name><name><surname>Tomashevsky</surname><given-names>M</given-names></name><name><surname>Marshall</surname><given-names>KA</given-names></name><name><surname>Phillippy</surname><given-names>KH</given-names></name><name><surname>Sherman</surname><given-names>PM</given-names></name><name><surname>Muertter</surname><given-names>RN</given-names></name><name><surname>Holko</surname><given-names>M</given-names></name><name><surname>Ayanbule</surname><given-names>O</given-names></name><name><surname>Yefanov</surname><given-names>A</given-names></name><name><surname>Soboleva</surname><given-names>A</given-names></name><article-title>NCBI GEO: archive for functional genomics json sets-10 years on</article-title><source>Nucleic Acids Res</source><year>2011</year><volume>39</volume><issue>Database</issue><fpage>D1005</fpage><lpage>D1010</lpage><pub-id pub-id-type="doi">10.1093/nar/gkq1184</pub-id><pub-id pub-id-type="pmid">21097893</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="book"><name><surname>Rivest</surname><given-names>R</given-names></name><source>The MD5 Message-Digest Algorithm</source><year>1992</year><publisher-name>US</publisher-name></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="book"><collab>National Institute of Standards and Technology</collab><source>FIPS 180-3, Secure Hash Standard, Federal Information Processing Standard (FIPS), Publication 180-3</source><year>2008</year><publisher-name>Tech. rep., Department of Commerce</publisher-name></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="book"><name><surname>Menezes</surname><given-names>AJ</given-names></name><name><surname>van Oorschot</surname><given-names>PC</given-names></name><name><surname>Vanstone</surname><given-names>SA</given-names></name><source>Handbook of Applied Cryptography</source><year>2001</year><publisher-name>CRC Press</publisher-name><ext-link ext-link-type="uri" xlink:href="http://www.cacr.math.uwaterloo.ca/hac/">http://www.cacr.math.uwaterloo.ca/hac/</ext-link></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="book"><name><surname>Carter</surname><given-names>JL</given-names></name><name><surname>Wegman</surname><given-names>MN</given-names></name><article-title>Universal classes of hash functions (Extended Abstract)</article-title><source>STOC '77: Proceedings of the ninth annual ACM symposium on Theory of computing</source><year>1977</year><publisher-name>New York, NY, USA: ACM</publisher-name><fpage>106</fpage><lpage>112</lpage></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><name><surname>Matsumoto</surname><given-names>M</given-names></name><name><surname>Nishimura</surname><given-names>T</given-names></name><article-title>Mersenne twister: a 623-dimensionally equidistributed uniform pseudo-random number generator</article-title><source>ACM Trans Model Comput Simul</source><year>1998</year><volume>8</volume><fpage>3</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1145/272991.272995</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="other"><article-title>PFFF: Supplementary text, materials, software and code (online)</article-title><ext-link ext-link-type="uri" xlink:href="http://biit.cs.ut.ee/pfff/">http://biit.cs.ut.ee/pfff/</ext-link></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="book"><name><surname>Fielding</surname><given-names>R</given-names></name><name><surname>Gettys</surname><given-names>J</given-names></name><name><surname>Mogul</surname><given-names>J</given-names></name><name><surname>Frystyk</surname><given-names>H</given-names></name><name><surname>Masinter</surname><given-names>L</given-names></name><name><surname>Leach</surname><given-names>P</given-names></name><name><surname>Berners-Lee</surname><given-names>T</given-names></name><article-title>Hypertext Transfer Protocol-HTTP/1.1</article-title><source>RFC 2616 (Draft Standard)</source><year>1999</year><publisher-name>Internet Engineering Task Force</publisher-name><ext-link ext-link-type="uri" xlink:href="http://www.ietf.org/rfc/rfc2616.txt">http://www.ietf.org/rfc/rfc2616.txt</ext-link><comment>Updated by RFCs 2817, 5785, 6266, 6585</comment></mixed-citation></ref></ref-list></back></article>